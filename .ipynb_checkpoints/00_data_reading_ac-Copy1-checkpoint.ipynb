{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b28d17",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mdsexton/capstone/blob/main/00_data_reading_ac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6EmkDJR93Ux7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EmkDJR93Ux7",
    "outputId": "65909919-fff9-4db1-9f09-7b3ee45a8bf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Oc2C5mTQ1G9u",
   "metadata": {
    "id": "Oc2C5mTQ1G9u"
   },
   "source": [
    "Zipped files by navigating to desired directory in terminal then executing `zip -r test.zip . -x \".*\" -x \"__MACOSX\"` \\\n",
    "Then uploading to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8mOJmhoAcgv",
   "metadata": {
    "id": "c8mOJmhoAcgv"
   },
   "outputs": [],
   "source": [
    "!unzip '/content/drive/MyDrive/general_assembly/code/capstone/arabic_characters/train.zip' -d '/content/drive/MyDrive/general_assembly/code/capstone/arabic_characters/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yr3XzsFYFCfE",
   "metadata": {
    "id": "yr3XzsFYFCfE"
   },
   "outputs": [],
   "source": [
    "!unzip '/content/drive/MyDrive/general_assembly/code/capstone/arabic_characters/test.zip' -d '/content/drive/MyDrive/general_assembly/code/capstone/arabic_characters/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "iWhv7zESFvZx",
   "metadata": {
    "id": "iWhv7zESFvZx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ueNSXd5NfK8D",
   "metadata": {
    "id": "ueNSXd5NfK8D"
   },
   "outputs": [],
   "source": [
    "drive_path = '/content/drive/MyDrive/general_assembly/code/capstone/arabic_characters/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ax-YpWuuQ37P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ax-YpWuuQ37P",
    "outputId": "6e54cdc2-88c4-46e1-fb06-85f078462320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13440 pictures converted\n"
     ]
    }
   ],
   "source": [
    "train_img_list = []\n",
    "train_label_list = []\n",
    "\n",
    "train_path = drive_path + 'train/'\n",
    "\n",
    "for file in os.listdir(train_path):\n",
    "    try:\n",
    "        char = load_img(train_path + file, color_mode='grayscale')\n",
    "        char_arr = img_to_array(char) / 255\n",
    "        train_img_list.append(char_arr)\n",
    "        train_label_list.append(file[-6:-4].replace('_', '0'))\n",
    "\n",
    "    except:\n",
    "        print(f'Error for file: {file}')\n",
    "\n",
    "print(f'{len(train_img_list)} pictures converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "iR1TwuZ1aqbn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iR1TwuZ1aqbn",
    "outputId": "a75633a0-1b40-492e-e5dd-fd53cc737b18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3360 pictures converted\n"
     ]
    }
   ],
   "source": [
    "test_img_list = []\n",
    "test_label_list = []\n",
    "\n",
    "test_path = drive_path + 'test/'\n",
    "\n",
    "for file in os.listdir(test_path):\n",
    "    try:\n",
    "        char = load_img(test_path + file, color_mode='grayscale')\n",
    "        char_arr = img_to_array(char) / 255\n",
    "        test_img_list.append(char_arr)\n",
    "        test_label_list.append(file[-6:-4].replace('_', '0'))\n",
    "    except:\n",
    "        print(f'Error for file: {file}')\n",
    "\n",
    "print(f'{len(test_img_list)} pictures converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4GxUZjVZjN8",
   "metadata": {
    "id": "c4GxUZjVZjN8"
   },
   "outputs": [],
   "source": [
    "class_dict = {'01' : ('alef', 'أ'),\n",
    "              '02' : ('beh', 'ب'),\n",
    "              '03' : ('teh', 'ت'),\n",
    "              '04' : ('theh', 'ث'),\n",
    "              '05' : ('jeem', 'ج'),\n",
    "              '06' : ('hah', 'ح'),\n",
    "              '07' : ('khah', 'خ'),\n",
    "              '08' : ('dal', 'د'),\n",
    "              '09' : ('thal', 'ذ'),\n",
    "              '10': ('reh', 'ر'),\n",
    "              '11': ('zain', 'ز'),\n",
    "              '12': ('seen', 'س'),\n",
    "              '13': ('sheen', 'ش'),\n",
    "              '14': ('sad', 'ص'),\n",
    "              '15': ('dad', 'ض'),\n",
    "              '16': ('tah', 'ط'),\n",
    "              '17': ('zah', 'ظ'),\n",
    "              '18': ('ain', 'ع'),\n",
    "              '19': ('ghain', 'غ'),\n",
    "              '20': ('feh', 'ف'),\n",
    "              '21': ('qaf', 'ق'),\n",
    "              '22': ('kaf', 'ك'),\n",
    "              '23': ('lam', 'ل'),\n",
    "              '24': ('meem', 'م'),\n",
    "              '25': ('noon', 'ن'),\n",
    "              '26': ('heh', 'ﻫ'),\n",
    "              '27': ('waw', 'و'),\n",
    "              '28': ('yeh', 'ي')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "qzUi-l5ObILq",
   "metadata": {
    "id": "qzUi-l5ObILq"
   },
   "outputs": [],
   "source": [
    "y_train = to_categorical(train_label_list)\n",
    "y_test = to_categorical(test_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5qmonZb3YnZC",
   "metadata": {
    "id": "5qmonZb3YnZC"
   },
   "outputs": [],
   "source": [
    "train_imgs = np.squeeze(train_img_list)\n",
    "test_imgs = np.squeeze(test_img_list)\n",
    "train_labels = train_label_list\n",
    "test_labels = test_label_list\n",
    "X_train = np.array(train_img_list)\n",
    "X_test = np.array(test_img_list)\n",
    "y_train = np.delete(y_train, 0, 1) # removing '0' class which doesn't exist in original dataset\n",
    "y_test = np.delete(y_test, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "Uo6T-rX1c2yD",
   "metadata": {
    "id": "Uo6T-rX1c2yD"
   },
   "outputs": [],
   "source": [
    "# listing each data set's name for reference later when unpickling\n",
    "data_names = ['train_imgs',\n",
    "              'test_imgs',\n",
    "              'train_labels',\n",
    "              'test_labels',\n",
    "              'X_train',\n",
    "              'X_test',\n",
    "              'y_train',\n",
    "              'y_test',\n",
    "              'class_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "n3FY2T8QYs2f",
   "metadata": {
    "id": "n3FY2T8QYs2f"
   },
   "outputs": [],
   "source": [
    "data = [train_imgs,\n",
    "        test_imgs,\n",
    "        train_labels,\n",
    "        test_labels,\n",
    "        X_train,\n",
    "        X_test,\n",
    "        y_train,\n",
    "        y_test,\n",
    "        class_dict,\n",
    "        data_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tECxFQjobAyq",
   "metadata": {
    "id": "tECxFQjobAyq"
   },
   "outputs": [],
   "source": [
    "with open(drive_path + 'arabchars.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "o7uhj4lBbUFJ",
   "metadata": {
    "id": "o7uhj4lBbUFJ"
   },
   "outputs": [],
   "source": [
    "with open(drive_path + 'arabchars.pkl', 'rb') as f:\n",
    "    ac_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "pEOz3nVCbgTB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEOz3nVCbgTB",
    "outputId": "0f671ba3-efd4-4f7a-d2fb-9e3cb31d7c9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_imgs',\n",
       " 'test_imgs',\n",
       " 'train_labels',\n",
       " 'test_labels',\n",
       " 'X_train',\n",
       " 'X_test',\n",
       " 'y_train',\n",
       " 'y_test',\n",
       " 'class_dict']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac_data[9]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "scratch_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
